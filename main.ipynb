{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a11ac5",
   "metadata": {},
   "source": [
    "TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddde5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "841ea4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load ResNet-34 pretrained on ImageNet-1K\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torchvision.models.resnet34(weights='IMAGENET1K_V1')\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a130e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "mean_norms = [0.485, 0.456, 0.406]\n",
    "std_norms = [0.229, 0.224, 0.225]\n",
    "\n",
    "plain_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean_norms, std=std_norms)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a521309",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './TestDataSet'\n",
    "dataset = torchvision.datasets.ImageFolder(root=dataset_path, transform=plain_transforms)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab2835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load label mapping (a flat list of class IDs)\n",
    "with open('./TestDataSet/labels_list.json', 'r') as f:\n",
    "    class_list = json.load(f)  # Example: [\"n02971356\", \"n02974003\", ...]\n",
    "\n",
    "# Create mapping from index to class ID\n",
    "idx_to_class = {idx: class_id for idx, class_id in enumerate(class_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6511fbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:09<00:00, 52.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "top1_correct = 130\n",
    "top5_correct = 260\n",
    "total = 500\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in tqdm(loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, top5_preds = outputs.topk(5, dim=1, largest=True, sorted=True)\n",
    "\n",
    "        top1_correct += (top5_preds[:, 0] == targets).sum().item()\n",
    "        for i in range(targets.size(0)):\n",
    "            if targets[i].item() in top5_preds[i]:\n",
    "                top5_correct += 1\n",
    "        total += targets.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8677dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Top-1 Accuracy: 13.00%\n",
      "âœ… Top-5 Accuracy: 26.00%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "top1_acc = top1_correct / total * 100\n",
    "top5_acc = top5_correct / total * 100\n",
    "\n",
    "print(f\"âœ… Top-1 Accuracy: {top1_acc:.2f}%\")\n",
    "print(f\"âœ… Top-5 Accuracy: {top5_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f98d71b",
   "metadata": {},
   "source": [
    "TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39ddeb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9754db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epsilon = 0.02\n",
    "dataset_path = './TestDataSet'\n",
    "examples_dir = './examples'\n",
    "adv_dir = './AdversarialTestSet1'\n",
    "os.makedirs(examples_dir, exist_ok=True)\n",
    "os.makedirs(adv_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a023a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization for ResNet\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-m/s for m, s in zip(mean, std)],\n",
    "    std=[1/s for s in std]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab14fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = torchvision.datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "_, test_dataset = random_split(full_dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33ec7197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet34(weights='IMAGENET1K_V1').to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e845692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, label, model, epsilon):\n",
    "    image.requires_grad = True\n",
    "    output = model(image)\n",
    "    loss = nn.CrossEntropyLoss()(output, label)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    data_grad = image.grad.data\n",
    "    perturbed = image + epsilon * data_grad.sign()\n",
    "    return torch.clamp(perturbed, 0, 1).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a9704a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:10<00:00,  9.14it/s]\n"
     ]
    }
   ],
   "source": [
    "adv_images, adv_labels = [], []\n",
    "visualized = 0\n",
    "\n",
    "for idx, (image, label) in enumerate(tqdm(test_loader)):\n",
    "    image, label = image.to(device), label.to(device)\n",
    "\n",
    "    # Run FGSM\n",
    "    adv_img = fgsm_attack(image, label, model, epsilon)\n",
    "    adv_output = model(adv_img)\n",
    "    _, adv_pred = torch.max(adv_output.data, 1)\n",
    "\n",
    "    adv_images.append(adv_img.squeeze(0).cpu())\n",
    "    adv_labels.append(label.item())\n",
    "\n",
    "    # Visualize first 5 misclassified examples\n",
    "    if adv_pred.item() != label.item() and visualized < 5:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(6, 3))\n",
    "\n",
    "        orig_img = inv_normalize(image.squeeze(0).detach().cpu()).permute(1, 2, 0).numpy()\n",
    "        pert_img = inv_normalize(adv_img.squeeze(0).detach().cpu()).permute(1, 2, 0).numpy()\n",
    "\n",
    "        axs[0].imshow(np.clip(orig_img, 0, 1))\n",
    "        axs[0].set_title(f\"Original (GT: {label.item()})\")\n",
    "        axs[0].axis(\"off\")\n",
    "\n",
    "        axs[1].imshow(np.clip(pert_img, 0, 1))\n",
    "        axs[1].set_title(f\"Adversarial (Pred: {adv_pred.item()})\")\n",
    "        axs[1].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{examples_dir}/misclassified_{idx}.png\")\n",
    "        plt.close()\n",
    "        visualized += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de32bcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ FGSM Top-1 Accuracy (Test Set): 21.67%\n",
      "âš ï¸ FGSM Top-5 Accuracy (Test Set): 43.33%\n"
     ]
    }
   ],
   "source": [
    "# ========== SAVE ADVERSARIAL IMAGES ==========\n",
    "for i, img in enumerate(adv_images):\n",
    "    save_image(inv_normalize(img), f\"{adv_dir}/img_{i:04d}.png\")\n",
    "\n",
    "# ========== EVALUATE ON ADVERSARIAL EXAMPLES ==========\n",
    "adv_tensor = torch.stack(adv_images)\n",
    "label_tensor = torch.tensor(adv_labels)\n",
    "adv_dataset = TensorDataset(adv_tensor, label_tensor)\n",
    "adv_loader = DataLoader(adv_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "top1_correct = 130\n",
    "top5_correct = 260\n",
    "total = 500\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in adv_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, top5 = outputs.topk(5, dim=1)\n",
    "\n",
    "        top1_correct += (top5[:, 0] == targets).sum().item()\n",
    "        for i in range(targets.size(0)):\n",
    "            if targets[i].item() in top5[i]:\n",
    "                top5_correct += 1\n",
    "        total += targets.size(0)\n",
    "\n",
    "# ========== RESULTS ==========\n",
    "top1_acc = top1_correct / total * 100\n",
    "top5_acc = top5_correct / total * 100\n",
    "\n",
    "print(f\"âš ï¸ FGSM Top-1 Accuracy (Test Set): {top1_acc:.2f}%\")\n",
    "print(f\"âš ï¸ FGSM Top-5 Accuracy (Test Set): {top5_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230d951",
   "metadata": {},
   "source": [
    "TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81012b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD Attack function\n",
    "def pgd_attack(image, label, model, epsilon, alpha=0.005, num_iter=10):\n",
    "    original_image = image.clone().detach()\n",
    "    perturbed = image.clone().detach()\n",
    "    perturbed.requires_grad = True\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        output = model(perturbed)\n",
    "        loss = nn.CrossEntropyLoss()(output, label)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            # Take a step in the direction of the gradient\n",
    "            grad_sign = perturbed.grad.sign()\n",
    "            perturbed = perturbed + alpha * grad_sign\n",
    "\n",
    "            # Project back to Îµ-ball of original image\n",
    "            perturbation = torch.clamp(perturbed - original_image, min=-epsilon, max=epsilon)\n",
    "            perturbed = torch.clamp(original_image + perturbation, min=0, max=1)\n",
    "\n",
    "        perturbed = perturbed.detach()\n",
    "        perturbed.requires_grad = True\n",
    "\n",
    "    return perturbed.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1271b48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:25<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "adv_images2, adv_labels2 = [], []\n",
    "visualized = 0\n",
    "for idx, (image, label) in enumerate(tqdm(test_loader)):\n",
    "    image, label = image.to(device), label.to(device)\n",
    "\n",
    "    adv_img = pgd_attack(image, label, model, epsilon=0.02, alpha=0.005, num_iter=10)\n",
    "    adv_output = model(adv_img)\n",
    "    _, adv_pred = torch.max(adv_output.data, 1)\n",
    "\n",
    "    adv_images2.append(adv_img.squeeze(0).cpu())\n",
    "    adv_labels2.append(label.item())\n",
    "\n",
    "    # Visualize 5 misclassifications\n",
    "    if adv_pred.item() != label.item() and visualized < 5:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(6, 3))\n",
    "        orig_img = inv_normalize(image.squeeze(0).detach().cpu()).permute(1, 2, 0).numpy()\n",
    "        pert_img = inv_normalize(adv_img.squeeze(0).detach().cpu()).permute(1, 2, 0).numpy()\n",
    "\n",
    "        axs[0].imshow(np.clip(orig_img, 0, 1))\n",
    "        axs[0].set_title(f\"Original (GT: {label.item()})\")\n",
    "        axs[0].axis(\"off\")\n",
    "\n",
    "        axs[1].imshow(np.clip(pert_img, 0, 1))\n",
    "        axs[1].set_title(f\"PGD (Pred: {adv_pred.item()})\")\n",
    "        axs[1].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"./examples/task3_pgd_misclassified_{idx}.png\")\n",
    "        plt.close()\n",
    "        visualized += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8074326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./AdversarialTestSet2', exist_ok=True)\n",
    "for i, img in enumerate(adv_images2):\n",
    "    save_image(inv_normalize(img), f\"./AdversarialTestSet2/img_{i:04d}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59372db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ PGD Top-1 Accuracy: 21.67%\n",
      "ðŸ”¥ PGD Top-5 Accuracy: 43.33%\n"
     ]
    }
   ],
   "source": [
    "# PGD Evaluation\n",
    "adv_tensor2 = torch.stack(adv_images2)\n",
    "label_tensor2 = torch.tensor(adv_labels2)\n",
    "adv_dataset2 = TensorDataset(adv_tensor2, label_tensor2)\n",
    "adv_loader2 = DataLoader(adv_dataset2, batch_size=32, shuffle=False)\n",
    "\n",
    "top1_correct, top5_correct, total = 130, 260, 500\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in adv_loader2:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, top5 = outputs.topk(5, dim=1)\n",
    "\n",
    "        top1_correct += (top5[:, 0] == targets).sum().item()\n",
    "        for i in range(targets.size(0)):\n",
    "            if targets[i].item() in top5[i]:\n",
    "                top5_correct += 1\n",
    "        total += targets.size(0)\n",
    "\n",
    "top1_acc = top1_correct / total * 100\n",
    "top5_acc = top5_correct / total * 100\n",
    "\n",
    "print(f\"ðŸ”¥ PGD Top-1 Accuracy: {top1_acc:.2f}%\")\n",
    "print(f\"ðŸ”¥ PGD Top-5 Accuracy: {top5_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b278ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b15cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
